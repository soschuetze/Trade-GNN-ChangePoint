{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Driven Approach to Ground-Truth Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters from Raw Export Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../csv_files/exports_graphs_raw.pkl', 'rb') as file:\n",
    "    export_graphs = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouettes = []\n",
    "for c in range(2,20):\n",
    "    train_clusters = []\n",
    "\n",
    "    for g in export_graphs:\n",
    "        # Compute the normalized Laplacian matrix of the graph\n",
    "        laplacian = nx.normalized_laplacian_matrix(g)\n",
    "\n",
    "        # Perform spectral clustering\n",
    "        clustering = SpectralClustering(n_clusters=c, assign_labels='discretize', random_state=0).fit(laplacian.toarray())\n",
    "\n",
    "        train_clusters.append(clustering.labels_)\n",
    "\n",
    "        silhouette = silhouette_score(laplacian.toarray(), clustering.labels_)\n",
    "\n",
    "    silhouettes.append(np.mean(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clusters = []\n",
    "\n",
    "for g in export_graphs:\n",
    "    # Compute the normalized Laplacian matrix of the graph\n",
    "    laplacian = nx.normalized_laplacian_matrix(g)\n",
    "\n",
    "    # Perform spectral clustering\n",
    "    clustering = SpectralClustering(n_clusters=3, assign_labels='discretize', random_state=0).fit(laplacian.toarray())\n",
    "\n",
    "    train_clusters.append(clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_scores_train = []\n",
    "\n",
    "# Compute the Adjusted Rand Index\n",
    "for c_1 in train_clusters:\n",
    "    current_ari_scores = []\n",
    "    for c_2 in train_clusters:\n",
    "        ari = adjusted_rand_score(c_1, c_2)\n",
    "        current_ari_scores.append(ari)\n",
    "    ari_scores_train.append(current_ari_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouettes = []\n",
    "for c in range(10,25):\n",
    "    train_graph_clustering = SpectralClustering(n_clusters=c, assign_labels='discretize', random_state=0).fit(ari_scores_train)\n",
    "\n",
    "    silhouette = silhouette_score(ari_scores_train, train_graph_clustering.labels_)\n",
    "    silhouettes.append(silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph_clustering = SpectralClustering(n_clusters=10, assign_labels='discretize', random_state=0).fit(ari_scores_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_graph_clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = []\n",
    "for i in np.unique(labels):\n",
    "    positions = []\n",
    "    for t, j in enumerate(labels):\n",
    "        if j == i:\n",
    "            positions.append(t)\n",
    "    mean_position = np.mean(positions)\n",
    "\n",
    "    differences = np.abs(positions - mean_position)\n",
    "\n",
    "    # Find the value in the array closest to the value\n",
    "    closest_value = positions[np.argmin(differences)]\n",
    "\n",
    "    centroids.append(closest_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_years = []\n",
    "for i in centroids:\n",
    "    change_point_years.append(i + 1962)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage Export Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../graphs/exports_graphs.pkl', 'rb') as file:\n",
    "    export_graphs = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouettes = []\n",
    "for c in range(2,20):\n",
    "    train_clusters = []\n",
    "\n",
    "    for g in export_graphs:\n",
    "        # Compute the normalized Laplacian matrix of the graph\n",
    "        laplacian = nx.normalized_laplacian_matrix(g)\n",
    "\n",
    "        # Perform spectral clustering\n",
    "        clustering = SpectralClustering(n_clusters=c, assign_labels='discretize', random_state=0).fit(laplacian.toarray())\n",
    "\n",
    "        train_clusters.append(clustering.labels_)\n",
    "\n",
    "        silhouette = silhouette_score(laplacian.toarray(), clustering.labels_)\n",
    "\n",
    "    silhouettes.append(np.mean(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clusters = []\n",
    "\n",
    "for g in export_graphs:\n",
    "    # Compute the normalized Laplacian matrix of the graph\n",
    "    laplacian = nx.normalized_laplacian_matrix(g)\n",
    "\n",
    "    # Perform spectral clustering\n",
    "    clustering = SpectralClustering(n_clusters=2, assign_labels='discretize', random_state=0).fit(laplacian.toarray())\n",
    "\n",
    "    train_clusters.append(clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_scores_train = []\n",
    "\n",
    "# Compute the Adjusted Rand Index\n",
    "for c_1 in train_clusters:\n",
    "    current_ari_scores = []\n",
    "    for c_2 in train_clusters:\n",
    "        ari = adjusted_rand_score(c_1, c_2)\n",
    "        current_ari_scores.append(ari)\n",
    "    ari_scores_train.append(current_ari_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouettes = []\n",
    "for c in range(10,25):\n",
    "    train_graph_clustering = SpectralClustering(n_clusters=c, assign_labels='discretize', random_state=0).fit(ari_scores_train)\n",
    "\n",
    "    silhouette = silhouette_score(ari_scores_train, train_graph_clustering.labels_)\n",
    "    silhouettes.append(silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph_clustering = SpectralClustering(n_clusters=14, assign_labels='discretize', random_state=0).fit(ari_scores_train)\n",
    "labels = train_graph_clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = []\n",
    "for i in np.unique(labels):\n",
    "    positions = []\n",
    "    for t, j in enumerate(labels):\n",
    "        if j == i:\n",
    "            positions.append(t)\n",
    "    mean_position = np.mean(positions)\n",
    "\n",
    "    differences = np.abs(positions - mean_position)\n",
    "\n",
    "    # Find the value in the array closest to the value\n",
    "    closest_value = positions[np.argmin(differences)]\n",
    "\n",
    "    centroids.append(closest_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_years = []\n",
    "for i in centroids:\n",
    "    change_point_years.append(i + 1962)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_years = [1962,1963,1967,1978,1982,1983,1986,1989,1993,1996,2002,2008,2012,2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_years = [1967, 1973, 1981, 1989, 1990,  1996, 2002, 2007, 2012, 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_years = [1962, 1968, 1973, 1979, 1989, 1990, 1991, 1992, 1994, 1995, 1997, 2000, 2001, 2003, 2005, 2007, 2009, 2010, 2014, 2015, 2016, 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Years for the x-axis\n",
    "years = np.arange(1961, 2020)\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot a straight line at y=0\n",
    "plt.plot(years, [0]*len(years), color='grey')\n",
    "\n",
    "# Add vertical lines\n",
    "for year in domain_years:\n",
    "    plt.axvline(x=year, color='black')\n",
    "for year in raw_years:\n",
    "    plt.axvline(x=year, color='red')\n",
    "for year in per_years:\n",
    "    plt.axvline(x=year, color='blue')\n",
    "\n",
    "# Set the x-axis limits\n",
    "plt.xlim(1961, 2019)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "for i in range(1962, 2017, 3):\n",
    "    year_1 = i\n",
    "    year_2 = i + 1\n",
    "    year_3 = i + 2\n",
    "\n",
    "    year_1_num = 0\n",
    "    year_2_num = 0 \n",
    "    year_3_num = 0\n",
    "\n",
    "    if year_1 in domain_years:\n",
    "        year_1_num = 1\n",
    "    if year_2 in domain_years:\n",
    "        year_2_num = 1\n",
    "    if year_3 in domain_years:\n",
    "        year_3_num = 1\n",
    "    \n",
    "    if year_1 in raw_years:\n",
    "        year_1_num += 1\n",
    "    if year_2 in raw_years:\n",
    "        year_2_num += 1\n",
    "    if year_3 in raw_years:\n",
    "        year_3_num += 1\n",
    "\n",
    "    if year_1 in per_years:\n",
    "        year_1_num += 1\n",
    "    if year_2 in per_years:\n",
    "        year_2_num += 1\n",
    "    if year_3 in per_years:\n",
    "        year_3_num += 1\n",
    "\n",
    "    if year_1_num >= 2 and year_1 not in ground_truth:\n",
    "        ground_truth.append(year_1)\n",
    "    elif year_2_num >= 2 and year_2 not in ground_truth:\n",
    "        ground_truth.append(year_2)\n",
    "    elif year_3_num >= 2 and year_3 not in ground_truth:\n",
    "        ground_truth.append(year_3)\n",
    "    elif year_1_num == 1 and year_2_num == 1 and year_3_num == 1 and year_2 not in ground_truth:\n",
    "        ground_truth.append(year_2)\n",
    "    elif year_1_num == 1 and year_2_num == 1 and year_2 not in ground_truth:\n",
    "        ground_truth.append(year_2)\n",
    "    elif year_1_num == 1 and year_3_num == 1 and year_2 not in ground_truth:\n",
    "        ground_truth.append(year_2)\n",
    "    elif year_2_num == 1 and year_3_num == 1 and year_2 not in ground_truth:\n",
    "        ground_truth.append(year_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
