{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import datetime as datetime\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from src.utils.CreateFeatures import CreateFeatures\n",
    "from src.pygcn.SiameseGNN import SiameseGNN\n",
    "from src.pygcn.GraphSAGE import SiameseGNN_GraphSAGE\n",
    "from src.pygcn.graph_isomorphism import SiameseGNN_GIN\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from src.utils.functions import dist_labels_to_changepoint_labels, dist_labels_to_changepoint_labels_adjusted\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch_geometric.data as data\n",
    "from src.synthetic_experiments.sample import sample_pairs\n",
    "from src.utils.misc import collate\n",
    "import itertools\n",
    "from src.pygcn.GAT import SiameseGNN_GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1962,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = ['ABW', 'AFG', 'AGO', 'ALB', 'AND', 'ARE', 'ARG', 'ARM', 'ASM',\n",
    "       'ATG', 'AUS', 'AUT', 'AZE', 'BDI', 'BEL', 'BEN', 'BFA', 'BGD',\n",
    "       'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BMU', 'BOL', 'BRA',\n",
    "       'BRB', 'BRN', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN',\n",
    "       'CIV', 'CMR', 'COD', 'COG', 'COL', 'COM', 'CPV', 'CRI', 'CUB',\n",
    "       'CUW', 'CYM', 'CYP', 'CZE', 'DEU', 'DMA', 'DNK', 'DOM', 'DZA',\n",
    "       'ECU', 'EGY', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', 'FRA', 'FSM',\n",
    "       'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC',\n",
    "       'GRD', 'GRL', 'GTM', 'GUM', 'GUY', 'HKG', 'HND', 'HRV', 'HTI',\n",
    "       'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', 'ISL', 'ISR', 'ITA',\n",
    "       'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KNA', 'KOR',\n",
    "       'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LCA', 'LKA', 'LSO', 'LTU',\n",
    "       'LUX', 'LVA', 'MAC', 'MAR', 'MDA', 'MDG', 'MDV', 'MEX', 'MHL',\n",
    "       'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MNP', 'MOZ', 'MRT',\n",
    "       'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR',\n",
    "       'NPL', 'NRU', 'NZL', 'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PLW',\n",
    "       'PNG', 'POL', 'PRT', 'PRY', 'PSE', 'PYF', 'QAT', 'ROU', 'RUS',\n",
    "       'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLB', 'SLE', 'SLV', 'SMR',\n",
    "       'SRB', 'SSD', 'STP', 'SUR', 'SVK', 'SVN', 'SWE', 'SWZ', 'SXM',\n",
    "       'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', 'TKM', 'TLS', 'TON',\n",
    "       'TTO', 'TUN', 'TUR', 'TUV', 'TZA', 'UGA', 'UKR', 'URY', 'USA',\n",
    "       'UZB', 'VCT', 'VEN', 'VNM', 'VUT', 'WSM', 'YEM', 'ZAF', 'ZMB',\n",
    "       'ZWE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src/pygcn/all_graphs.pkl\", \"rb\") as f:         \n",
    "    all_graphs = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisis_years = [1962, 1967, 1973, 1978, 1981, 1989, 1993, 1996, 2002, 2007, 2012, 2014, 2016]\n",
    "phases = []\n",
    "p = -1\n",
    "for i in range(1962,2019):\n",
    "    if i in crisis_years:\n",
    "        p += 1\n",
    "    phases.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = dist_labels_to_changepoint_labels(phases)\n",
    "# graph_pairs = sample_pairs(all_graphs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('graph_pairs_nogdp.pkl', 'wb') as f:\n",
    "#     pkl.dump(graph_pairs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('graph_pairs.pkl', 'rb') as f:\n",
    "#     graph_pairs = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('test_data.pkl', 'rb') as f:\n",
    "#     test_data = pkl.load(f)\n",
    "\n",
    "# with open('val_data.pkl', 'rb') as f:\n",
    "#     val_data = pkl.load(f)\n",
    "\n",
    "# with open('train_data.pkl', 'rb') as f:\n",
    "#     train_data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data_indices.pkl', 'rb') as f:\n",
    "    test_indices = pkl.load(f)\n",
    "\n",
    "with open('val_data_indices.pkl', 'rb') as f:\n",
    "    val_indices = pkl.load(f)\n",
    "\n",
    "with open('train_data_indices.pkl', 'rb') as f:\n",
    "    train_indices = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indices, test_indices = train_test_split(np.arange(len(graph_pairs)), test_size=0.40, random_state=42)\n",
    "# test_indices, val_indices = train_test_split(test_indices, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_pairs_train = [graph_pairs[i] for i in train_indices]\n",
    "# graph_pairs_test = [graph_pairs[i] for i in test_indices]\n",
    "# graph_pairs_val = [graph_pairs[i] for i in val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# positive_samples = [item for item in graph_pairs_train if item[2] == 1]\n",
    "# negative_samples = [item for item in graph_pairs_train if item[2] == 0]\n",
    "\n",
    "# # Calculate the difference in count\n",
    "# diff = len(negative_samples) - len(positive_samples)\n",
    "\n",
    "# # Upsample positive samples\n",
    "# if diff > 0:\n",
    "#     positive_samples_upsampled = random.sample(positive_samples, k=abs(diff))\n",
    "#     balanced_data = negative_samples + positive_samples+ positive_samples_upsampled\n",
    "# # Downsample negative samples\n",
    "# elif diff < 0:\n",
    "#     negative_samples_downsampled = random.sample(negative_samples, k=abs(diff))\n",
    "#     balanced_data = negative_samples_downsampled + negative_samples+ positive_samples\n",
    "# else:\n",
    "#     balanced_data = graph_pairs_train\n",
    "\n",
    "# random.shuffle(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_data_nogdp.pkl', 'wb') as f:\n",
    "#     pkl.dump(balanced_data, f)\n",
    "\n",
    "# with open('val_data_nogdp.pkl', 'wb') as f:\n",
    "#     pkl.dump(graph_pairs_val, f)\n",
    "    \n",
    "# with open('test_data_nogdp.pkl', 'wb') as f:\n",
    "#     pkl.dump(graph_pairs_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_data_indices_nogdp.pkl', 'wb') as f:\n",
    "#     pkl.dump(train_indices, f)\n",
    "\n",
    "# with open('val_data_indices_nogdp.pkl', 'wb') as f:\n",
    "#     pkl.dump(val_indices, f)\n",
    "    \n",
    "# with open('test_data_indices_nogdp.pkl', 'wb') as f:\n",
    "#     pkl.dump(test_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.pkl', 'rb') as f:\n",
    "    balanced_data = pkl.load(f)\n",
    "\n",
    "with open('val_data.pkl', 'rb') as f:\n",
    "    graph_pairs_val = pkl.load(f)\n",
    "    \n",
    "with open('test_data.pkl', 'rb') as f:\n",
    "    graph_pairs_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sGNN with GCN Encoder and 3 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "import numpy as np\n",
    "\n",
    "def run_model_normal(model, type, training_data_pairs, val_data_pairs, hyperparameters, sort_k, hidden_units, dropout_rate, num_folds=5, num_epochs=20):\n",
    "    \n",
    "    val_acc = 0\n",
    "    val_f1 = 0\n",
    "    val_f2 = 0\n",
    "    val_f05 = 0\n",
    "\n",
    "    val_loss_arr = []\n",
    "    train_loss_arr = []\n",
    "\n",
    "    model = SiameseGNN_GraphSAGE(sort_k, 27, dropout_rate, 8)\n",
    "        \n",
    "    torch.manual_seed(42)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0001)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    criterion = nn.BCELoss()  # Changed to BCEWithLogitsLoss for numerical stability\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for (graph1, graph2, labels) in training_data_pairs:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(graph1, graph2)\n",
    "\n",
    "            loss = criterion(out, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            val_pred = []\n",
    "            val_truth = []\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for (graph1, graph2, labels) in val_data_pairs:\n",
    "                out = model(graph1, graph2)\n",
    "\n",
    "                val_loss = criterion(out, labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                predictions = torch.round(out)\n",
    "\n",
    "                val_pred.extend(predictions.cpu().numpy())\n",
    "                val_truth.extend(labels.cpu().numpy())\n",
    "\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            val_loss = sum(val_losses) / len(val_losses)\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "        val_f1 = f1_score(val_truth, val_pred)\n",
    "        val_f2 = fbeta_score(y_true=val_truth, y_pred=val_pred, beta=2)\n",
    "        val_f05 = fbeta_score(y_true=val_truth, y_pred=val_pred, beta=1 / 2)\n",
    "\n",
    "        train_loss_arr.append(sum(train_losses) / len(train_losses))\n",
    "        val_loss_arr.append(val_loss)\n",
    "        print(f'Epoch: {epoch + 1}, Training Loss: {sum(train_losses) / len(train_losses)}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, F1 Score: {val_f1}, F2 Score: {val_f2}, F0.5 Score: {val_f05}')\n",
    "\n",
    "    model_name = f\"models/real_data/sage-f{hyperparameters}_window.pt\"\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "import numpy as np\n",
    "\n",
    "def run_model_cv(model, type, data_pairs, num_folds=5, num_epochs=30):\n",
    "    \n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "\n",
    "    val_acc = 0\n",
    "    val_f1 = 0\n",
    "    val_f2 = 0\n",
    "    val_f05 = 0\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(data_pairs)):\n",
    "        print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "        model = SiameseGNN_GraphSAGE(50, 27, 0.1, 16)\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0001)\n",
    "        scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "        criterion = nn.BCELoss()  # Changed to BCEWithLogitsLoss for numerical stability\n",
    "\n",
    "        # Prepare data for current fold\n",
    "        training_data_pairs = [data_pairs[i] for i in train_index]\n",
    "        validation_data_pairs = [data_pairs[i] for i in val_index]\n",
    "\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            for (graph1, graph2, labels) in training_data_pairs:\n",
    "                optimizer.zero_grad()\n",
    "                out = model(graph1, graph2)\n",
    "\n",
    "                loss = criterion(out, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_losses = []\n",
    "                val_pred = []\n",
    "                val_truth = []\n",
    "\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for (graph1, graph2, labels) in validation_data_pairs:\n",
    "                    out = model(graph1, graph2)\n",
    "\n",
    "                    val_loss = criterion(out, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                    predictions = torch.round(out)\n",
    "\n",
    "                    val_pred.extend(predictions.cpu().numpy())\n",
    "                    val_truth.extend(labels.cpu().numpy())\n",
    "\n",
    "                    correct += (predictions == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                val_loss = sum(val_losses) / len(val_losses)\n",
    "                val_accuracy = correct / total\n",
    "\n",
    "            val_f1 = f1_score(val_truth, val_pred)\n",
    "            val_f2 = fbeta_score(y_true=val_truth, y_pred=val_pred, beta=2)\n",
    "            val_f05 = fbeta_score(y_true=val_truth, y_pred=val_pred, beta=1 / 2)\n",
    "\n",
    "            print(f'Fold: {fold + 1}, Epoch: {epoch + 1}, Training Loss: {sum(train_losses) / len(train_losses)}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, Validation F1 Score: {val_f1}, Validation F2 Score: {val_f2}, Validation F0.5 Score: {val_f05}')\n",
    "\n",
    "            if epoch ==19:\n",
    "                val_acc += val_accuracy\n",
    "                val_f1 += val_f1\n",
    "                val_f2 += val_f2\n",
    "                val_f05 += val_f05\n",
    "\n",
    "        model_name = f\"models/real_data/sage-fold{fold}.pt\"\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    fold_scores.append((val_acc / 5, val_f1 / 5, val_f2 / 5, val_f05 / 5))\n",
    "\n",
    "    return fold_scores, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = balanced_data + graph_pairs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gcn\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = balanced_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN_GraphSAGE(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"sage\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = balanced_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN_GIN(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gin\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN_GAT(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gat\", train_data)\n",
    "\n",
    "fold_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sGNN with Feature Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_dicts/mis_norm.pkl\", \"rb\") as f:\n",
    "    feat_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(years, graphs, feat_dict, dim):\n",
    "\n",
    "    zeros = torch.zeros(dim)\n",
    "\n",
    "    for i in range(len(years)):\n",
    "        new_x = torch.empty(0, dim)\n",
    "        year = years[i]\n",
    "\n",
    "        feat_dict_year = feat_dict[year].combined_features\n",
    "\n",
    "        for j, country in enumerate(all_nodes):\n",
    "            if j == 0:\n",
    "                new_x = torch.stack([zeros])\n",
    "\n",
    "            elif country in feat_dict_year[\"country_code\"].values:\n",
    "                tensor_before = graphs[i].x[j]\n",
    "                country_row = feat_dict_year[feat_dict_year[\"country_code\"] == country]\n",
    "                country_row = country_row.drop(columns = [\"country_code\", \"current_gdp_growth\"])\n",
    "                row_values = country_row.values.tolist()\n",
    "                row_tensor = torch.tensor(row_values)[0]\n",
    "                combined_values = torch.cat((tensor_before, row_tensor))\n",
    "\n",
    "                new_x = torch.cat((new_x, combined_values.unsqueeze(0)), dim=0)\n",
    "\n",
    "            else:\n",
    "                new_x = torch.cat((new_x, zeros.unsqueeze(0)), dim=0)\n",
    "\n",
    "        graphs[i].x = new_x\n",
    "\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src/pygcn/all_graphs.pkl\", \"rb\") as f:         \n",
    "    all_graphs = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graphs = add_features(years, all_graphs, feat_dict, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 positive and 168 negative examples\n",
      "27 positive and 18 negative examples\n",
      "33 positive and 32 negative examples\n"
     ]
    }
   ],
   "source": [
    "#For window sampling\n",
    "train_graphs = all_graphs[:34]\n",
    "val_graphs = all_graphs[34:45]\n",
    "test_graphs = all_graphs[45:]\n",
    "\n",
    "labels = dist_labels_to_changepoint_labels(phases)\n",
    "graph_pairs_train = sample_pairs(train_graphs,labels[:34])\n",
    "graph_pairs_val = sample_pairs(val_graphs,labels[34:45])\n",
    "graph_pairs_test = sample_pairs(test_graphs,labels[45:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798 positive and 540 negative examples\n"
     ]
    }
   ],
   "source": [
    "# labels = dist_labels_to_changepoint_labels(phases)\n",
    "# graph_pairs = sample_pairs(all_graphs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_pairs_train = [graph_pairs[i] for i in train_indices]\n",
    "# graph_pairs_test = [graph_pairs[i] for i in test_indices]\n",
    "# graph_pairs_val = [graph_pairs[i] for i in val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "positive_samples = [item for item in graph_pairs_train if item[2] == 1]\n",
    "negative_samples = [item for item in graph_pairs_train if item[2] == 0]\n",
    "\n",
    "# Calculate the difference in count\n",
    "diff = len(negative_samples) - len(positive_samples)\n",
    "\n",
    "# Upsample positive samples\n",
    "if diff > 0:\n",
    "    positive_samples_upsampled = random.sample(positive_samples, k=abs(diff))\n",
    "    balanced_data = negative_samples + positive_samples+ positive_samples_upsampled\n",
    "# Downsample negative samples\n",
    "elif diff < 0:\n",
    "    negative_samples_downsampled = random.sample(negative_samples, k=len(negative_samples))\n",
    "    balanced_data = negative_samples_downsampled + negative_samples+ positive_samples\n",
    "else:\n",
    "    balanced_data = graph_pairs_train\n",
    "\n",
    "random.shuffle(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = balanced_data + graph_pairs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gcn\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:03<01:14,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.7185826454470023, Validation Loss: 0.7004932847889986, Validation Accuracy: 0.43636363636363634, F1 Score: 0.6075949367088608, F2 Score: 0.631578947368421, F0.5 Score: 0.5853658536585366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:07<01:08,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.695782827864949, Validation Loss: 0.6884372331879356, Validation Accuracy: 0.5818181818181818, F1 Score: 0.735632183908046, F2 Score: 0.8080808080808081, F0.5 Score: 0.6751054852320675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:11<01:03,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.6961857327381443, Validation Loss: 0.6907454338940707, Validation Accuracy: 0.45454545454545453, F1 Score: 0.625, F2 Score: 0.6544502617801047, F0.5 Score: 0.5980861244019139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:14<00:59,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.6890826230595305, Validation Loss: 0.6850487600673328, Validation Accuracy: 0.6, F1 Score: 0.75, F2 Score: 0.8291457286432161, F0.5 Score: 0.6846473029045643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:18<00:56,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.683488788877822, Validation Loss: 0.6916092699224299, Validation Accuracy: 0.43636363636363634, F1 Score: 0.6075949367088608, F2 Score: 0.631578947368421, F0.5 Score: 0.5853658536585366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:22<00:51,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.6816287615498725, Validation Loss: 0.6992807182398709, Validation Accuracy: 0.38181818181818183, F1 Score: 0.5526315789473685, F2 Score: 0.5614973262032086, F0.5 Score: 0.5440414507772021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:26<00:47,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 0.6789664349356469, Validation Loss: 0.7202501567927274, Validation Accuracy: 0.36363636363636365, F1 Score: 0.5070422535211268, F2 Score: 0.4945054945054945, F0.5 Score: 0.5202312138728323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:29<00:44,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 0.6716306107770268, Validation Loss: 0.7251970740881833, Validation Accuracy: 0.4, F1 Score: 0.5714285714285714, F2 Score: 0.5851063829787234, F0.5 Score: 0.5583756345177665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:33<00:40,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 0.664163143546493, Validation Loss: 0.7174176855520769, Validation Accuracy: 0.41818181818181815, F1 Score: 0.5897435897435898, F2 Score: 0.6084656084656085, F0.5 Score: 0.572139303482587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:37<00:36,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 0.6497800676011581, Validation Loss: 0.7381803929805756, Validation Accuracy: 0.4, F1 Score: 0.5714285714285714, F2 Score: 0.5851063829787234, F0.5 Score: 0.5583756345177665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:40<00:33,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss: 0.6390265133972848, Validation Loss: 0.7403963760896163, Validation Accuracy: 0.41818181818181815, F1 Score: 0.5897435897435898, F2 Score: 0.6084656084656085, F0.5 Score: 0.572139303482587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:44<00:29,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss: 0.6343357744530885, Validation Loss: 0.7342462442137978, Validation Accuracy: 0.4727272727272727, F1 Score: 0.6419753086419753, F2 Score: 0.6770833333333334, F0.5 Score: 0.6103286384976526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:48<00:25,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Training Loss: 0.6283908548914356, Validation Loss: 0.7357848243279891, Validation Accuracy: 0.4727272727272727, F1 Score: 0.6419753086419753, F2 Score: 0.6770833333333334, F0.5 Score: 0.6103286384976526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:51<00:22,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss: 0.6296301604707218, Validation Loss: 0.7335057556629181, Validation Accuracy: 0.4727272727272727, F1 Score: 0.6419753086419753, F2 Score: 0.6770833333333334, F0.5 Score: 0.6103286384976526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:55<00:18,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Training Loss: 0.633835232960998, Validation Loss: 0.7290815862742337, Validation Accuracy: 0.4727272727272727, F1 Score: 0.6419753086419753, F2 Score: 0.6770833333333334, F0.5 Score: 0.6103286384976526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:59<00:14,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss: 0.6332477681512532, Validation Loss: 0.7335523675788532, Validation Accuracy: 0.4727272727272727, F1 Score: 0.6419753086419753, F2 Score: 0.6770833333333334, F0.5 Score: 0.6103286384976526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:03<00:11,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Training Loss: 0.6180789572057737, Validation Loss: 0.7338763583790172, Validation Accuracy: 0.4727272727272727, F1 Score: 0.6419753086419753, F2 Score: 0.6770833333333334, F0.5 Score: 0.6103286384976526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:06<00:11,  3.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msort_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_units\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m SiameseGNN_GraphSAGE(sort_k, input_dim, dropout \u001b[38;5;241m=\u001b[39m dropout_rate, nhidden\u001b[38;5;241m=\u001b[39mhidden_units)\n\u001b[0;32m---> 15\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbalanced_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_pairs_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 32\u001b[0m, in \u001b[0;36mrun_model_normal\u001b[0;34m(model, type, training_data_pairs, val_data_pairs, hyperparameters, sort_k, hidden_units, dropout_rate, num_folds, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (graph1, graph2, labels) \u001b[38;5;129;01min\u001b[39;00m training_data_pairs:\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, labels)\n\u001b[1;32m     35\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/src/pygcn/GraphSAGE.py:44\u001b[0m, in \u001b[0;36mSiameseGNN_GraphSAGE.forward\u001b[0;34m(self, data1, data2)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data1, data2):\n\u001b[0;32m---> 44\u001b[0m     out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     out2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn(data2)\n\u001b[1;32m     47\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity(out1, out2)\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/src/pygcn/GraphSAGE.py:19\u001b[0m, in \u001b[0;36mGraphSAGE.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     16\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat(), data\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#x = torch.eye(400, 400)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\u001b[38;5;241m.\u001b[39mrelu()\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/var/folders/qh/0wyfgfcs3399gr_m2wrrtnzc0000gn/T/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_tku6ql1b.py:214\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    206\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    207\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[1;32m    208\u001b[0m                 index\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    209\u001b[0m                 ptr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mptr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    210\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    211\u001b[0m             )\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:625\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    610\u001b[0m     inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    615\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/experimental.py:117\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_dynamic_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:128\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:36\u001b[0m, in \u001b[0;36mMeanAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     34\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:182\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     80\u001b[0m     count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     82\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 83\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out \u001b[38;5;241m/\u001b[39m broadcast(count, out, dim)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# in case the input does not require gradients:\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = balanced_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [0.001]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [32]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    hyperparameters = f\"{lr}_{dropout_rate}_{sort_k}_{hidden_units}\"\n",
    "    model = SiameseGNN_GraphSAGE(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    train_losses, val_losses = run_model_normal(model, \"sage\", balanced_data, graph_pairs_val, hyperparameters, sort_k, hidden_units, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_times = [t-1962 for t in crisis_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_times = [i-45 for i in cp_times if i >=45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'results/mis-norm-no-gdp-window-data.p', 'wb') as f:\n",
    "    pkl.dump(test_graphs, f)\n",
    "\n",
    "with open(f'results/mis-norm-no-gdp-window-labels.p', 'wb') as f:\n",
    "    pkl.dump(labels[45:], f)\n",
    "\n",
    "with open(f'results/window-times.json', 'w') as f:\n",
    "    json.dump(window_times, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN_GIN(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gin\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:04<01:30,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.6257682449571164, Validation Loss: 0.632557641918009, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:09<01:24,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.6156059147096148, Validation Loss: 0.6331272997639396, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:13<01:18,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.6144748173932978, Validation Loss: 0.6322964321483265, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:18<01:13,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.6165808291040002, Validation Loss: 0.6325579003854231, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:22<01:07,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.610728214078196, Validation Loss: 0.6351239957592704, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:27<01:03,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.6101606878686079, Validation Loss: 0.6344550587914207, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:31<00:58,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 0.6149208007011822, Validation Loss: 0.634529028155587, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:36<00:53,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 0.6023063618231584, Validation Loss: 0.6395433041182431, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:40<00:49,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 0.5987414914231461, Validation Loss: 0.6383965470574119, Validation Accuracy: 0.6727272727272727, F1 Score: 0.8043478260869565, F2 Score: 0.9113300492610837, F0.5 Score: 0.7198443579766537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:45<00:44,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 0.5686454288462267, Validation Loss: 0.6595380734313618, Validation Accuracy: 0.6363636363636364, F1 Score: 0.7777777777777778, F2 Score: 0.8706467661691543, F0.5 Score: 0.7028112449799196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:47<00:47,  4.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msort_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_units\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m SiameseGNN_GAT(sort_k, input_dim, dropout \u001b[38;5;241m=\u001b[39m dropout_rate, nhidden\u001b[38;5;241m=\u001b[39mhidden_units)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mrun_model_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_pairs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_pairs_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m, in \u001b[0;36mrun_model_normal\u001b[0;34m(model, type, training_data_pairs, val_data_pairs, hyperparameters, num_folds, num_epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m out \u001b[38;5;241m=\u001b[39m model(graph1, graph2)\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, labels)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     34\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN_GAT(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gat\", train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Feature Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1962,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_dicts/random_logged.pkl\", \"rb\") as f:\n",
    "    feat_dict_random = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src/pygcn/graphs_nogdp.pkl\", \"rb\") as f:         \n",
    "    all_graphs = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graphs = add_features(years, all_graphs, feat_dict_random, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dist_labels_to_changepoint_labels(phases)\n",
    "graph_pairs = sample_pairs(all_graphs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pairs_train = [graph_pairs[i] for i in train_indices]\n",
    "graph_pairs_test = [graph_pairs[i] for i in test_indices]\n",
    "graph_pairs_val = [graph_pairs[i] for i in val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "positive_samples = [item for item in graph_pairs_train if item[2] == 1]\n",
    "negative_samples = [item for item in graph_pairs_train if item[2] == 0]\n",
    "\n",
    "# Calculate the difference in count\n",
    "diff = len(negative_samples) - len(positive_samples)\n",
    "\n",
    "# Upsample positive samples\n",
    "if diff > 0:\n",
    "    positive_samples_upsampled = random.sample(positive_samples, k=abs(diff))\n",
    "    balanced_data = negative_samples + positive_samples+ positive_samples_upsampled\n",
    "# Downsample negative samples\n",
    "elif diff < 0:\n",
    "    negative_samples_downsampled = random.sample(negative_samples, k=len(negative_samples))\n",
    "    balanced_data = negative_samples_downsampled + negative_samples+ positive_samples\n",
    "else:\n",
    "    balanced_data = graph_pairs_train\n",
    "\n",
    "random.shuffle(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = balanced_data + graph_pairs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gcn\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN_GraphSAGE(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"sage\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN_GAT(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gin\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].x.shape[1]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-4]\n",
    "dropout_rates = [0.1]\n",
    "sort_k_values = [50]\n",
    "hidden_units_values = [16]\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "hyperparameter_combinations = list(itertools.product(learning_rates, dropout_rates, sort_k_values, hidden_units_values))\n",
    "\n",
    "for lr, dropout_rate, sort_k, hidden_units in hyperparameter_combinations:\n",
    "    model = SiameseGNN_GIN(sort_k, input_dim, dropout = dropout_rate, nhidden=hidden_units)\n",
    "    fold_scores = run_model_cv(model, \"gat\", train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str):\n",
    "\n",
    "    model = SiameseGNN_GraphSAGE(50, 27, dropout = 0.05, nhidden=16)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseGNN_GraphSAGE(\n",
       "  (gnn): GraphSAGE(\n",
       "    (conv1): SAGEConv(27, 128, aggr=mean)\n",
       "    (conv2): SAGEConv(128, 16, aggr=mean)\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.05, inplace=False)\n",
       "  (similarity): PairwiseDistance()\n",
       "  (fc1): Linear(in_features=50, out_features=128, bias=True)\n",
       "  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('models/real_data/mis_logged_window.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5909090909090909, F1 Score: 0.6582278481012658, F2 Score: 0.7182320441988951, F0.5 Score: 0.6074766355140186\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (graph1, graph2, label) in graph_pairs_test:\n",
    "        output = model(graph1, graph2)\n",
    "        predictions = torch.round(output)\n",
    "        y_true.append(label.numpy())\n",
    "        y_pred.append(predictions.numpy())\n",
    "\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "acc = np.mean(y_true == y_pred)\n",
    "val_f1 = f1_score(y_true, y_pred)\n",
    "val_f2 = fbeta_score(y_true, y_pred, beta=2)\n",
    "val_f05 = fbeta_score(y_true, y_pred, beta=1 / 2)\n",
    "\n",
    "print(f'Accuracy: {acc}, F1 Score: {val_f1}, F2 Score: {val_f2}, F0.5 Score: {val_f05}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
